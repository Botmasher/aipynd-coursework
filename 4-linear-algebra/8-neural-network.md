# Lesson 8: Linear Algebra in a Neural Network

(relevant sections given in parens)
- neural nets, lines with weights (4)
- input connected to hidden layer, hidden to output (5)
    - no limit or correlation to number of each in layers
    - model bias
- feed-forward process (6-7)
    - weights are a matrix, input and output are vectors
    - find hidden layer vector multiplying input vector by weight matrix
    - to find output it's the same except hidden is vector
